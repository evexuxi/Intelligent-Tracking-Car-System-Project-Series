{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行完上面的代码块后，就可以实时的看到摄像头拍摄到的画面。接下来在第二个代码块中我们希望创建一个建立一个叫dataset的文件夹，里面有五个子文件夹，分别是 stop、left、right、forward、backward，用于分类放置每类手势的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "stop_dir = 'dataset/stop'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(stop_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了采集数据方便，我们需要创建5个按键和对应的文本框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_layout = widgets.Layout(width='128px', height='64px')\n",
    "stop_button = widgets.Button(description='add stop', button_style='success', layout=button_layout)\n",
    "stop_count = widgets.IntText(layout=button_layout, value=len(os.listdir(stop_dir)))\n",
    "\n",
    "display(widgets.HBox([stop_count, stop_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，这些按钮什么也做不了。我们必须附加上功能函数，已保存图像为每个类别的按钮 ''n_click ''。我们将保存'' Image ''部件(而不是相机)的值，因为它已经是压缩的JPEG格式! 为了确保不会重复任何文件名(即使是在不同的机器上!)，我们将使用python中的''uuid ''包，它定义了''uuid ''方法来生成唯一标识符。这个惟一标识符由当前时间和机器地址等信息生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "def save_snapshot(directory):\n",
    "    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "\n",
    "def save_stop():\n",
    "    global stop_dir, stop_count\n",
    "    save_snapshot(stop_dir)\n",
    "    stop_count.value = len(os.listdir(stop_dir))\n",
    "    \n",
    "    \n",
    "# attach the callbacks, we use a 'lambda' function to ignore the\n",
    "# parameter that the on_click event would provide to our function\n",
    "# because we don't need it.\n",
    "stop_button.on_click(lambda x: save_stop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image)\n",
    "display(widgets.HBox([stop_count, stop_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便采集数据，我们可以将按钮和摄像头的画面放在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你将代码全部完善以后，上面的按钮就可以将图像保存到相应的目录中了。你可以使用Jupyter左边目录文件浏览器来查看这些文件! 现在你就可以开始采集手势图片了。当你采集完成图片以后记得运行下面的代码将dataset文件进行压缩，然后将压缩后的文件下载到自己的电脑上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r -q dataset.zip dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码请同学们在自己的电脑上运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "def data_calculate(folder_path, class_name):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True,\n",
    "                           max_num_hands=2,\n",
    "                           min_detection_confidence=0.5,\n",
    "                           min_tracking_confidence=0.5)\n",
    "    fail_img = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img = cv2.imread(folder_path + '/' + img_name)\n",
    "        # Flip Horizontal\n",
    "        img = cv2.flip(img, 1)\n",
    "        # BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        try:\n",
    "            results = hands.process(img)\n",
    "\n",
    "            with open(f'data.csv', 'a') as f:\n",
    "                for i in results.multi_hand_landmarks[0].landmark:\n",
    "                    # print(i.x, i.y, i.z)\n",
    "                    f.write(f'{i.x},{i.y},{i.z},')\n",
    "                f.write(class_name)\n",
    "                f.write('\\n')\n",
    "        except:\n",
    "            fail_img.append(img_name)\n",
    "\n",
    "    for i in fail_img:\n",
    "        print(f\"Can not extract image {i}\")\n",
    "    print(len(fail_img))\n",
    "\n",
    "\n",
    "data_calculate(folder_path='dataset/stop', class_name=\"0\")\n",
    "#data_calculate(folder_path='dataset/left', class_name=\"1\")\n",
    "#data_calculate(folder_path='dataset/right', class_name=\"2\")\n",
    "#data_calculate(folder_path='dataset/forward', class_name=\"3\")\n",
    "#data_calculate(folder_path='dataset/backward', class_name=\"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请同学们认真阅读并理解上述代码，自行提取出剩下四种手势的手部关键点数据制作成数据集。提取好的手部关键点数据集data.csv将用来训练后续的神经网络模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    readbook = pd.read_csv(f'{filename}.csv')\n",
    "    nplist = readbook.T.to_numpy()\n",
    "    data = nplist[0:-1].T\n",
    "    data = np.float64(data)\n",
    "    target = nplist[-1]\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def random_number(data_size, key):\n",
    "    number_set = []\n",
    "    for i in range(data_size):\n",
    "        number_set.append(i)\n",
    "\n",
    "    if key == 1:\n",
    "        random.shuffle(number_set)\n",
    "\n",
    "    return number_set\n",
    "\n",
    "\n",
    "def split_dataset(data_set, target_set, rate, ifsuf):\n",
    "    train_size = int((1 - rate) * len(data_set))  # 计算训练集的数据个数\n",
    "    data_index = random_number(len(data_set), ifsuf)\n",
    "    x_train = data_set[data_index[:train_size]]\n",
    "    x_test = data_set[data_index[train_size:]]\n",
    "    y_train = target_set[data_index[:train_size]]\n",
    "    y_test = target_set[data_index[train_size:]]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def inputtotensor(inputtensor, labeltensor):  # 将数据集的输入和标签转为tensor格式\n",
    "    inputtensor = np.array(inputtensor)\n",
    "    inputtensor = torch.FloatTensor(inputtensor)\n",
    "\n",
    "    labeltensor = np.array(labeltensor)\n",
    "    labeltensor = labeltensor.astype(float)\n",
    "    labeltensor = torch.LongTensor(labeltensor)\n",
    "\n",
    "    return inputtensor, labeltensor\n",
    "\n",
    "\n",
    "def addbatch(data_train, data_test, batchsize):\n",
    "    data = TensorDataset(data_train, data_test)\n",
    "    data_loader = DataLoader(data, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "# 定义神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_channels=63, n_classes=5, dropout_probability=0.2):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_probability = dropout_probability\n",
    "        self.all_conv_high = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "        self.all_conv_low = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "        self.all_residual = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=9 * 7, out_features=512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=512, out_features=n_classes)\n",
    "        )\n",
    "        for module in itertools.chain(self.all_conv_high, self.all_conv_low, self.all_residual):\n",
    "            for layer in module:\n",
    "                if layer.__class__.__name__ == \"Conv1d\":\n",
    "                    torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                    torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "        for layer in self.fc:\n",
    "            if layer.__class__.__name__ == \"Linear\":\n",
    "                torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        input = input.unsqueeze(1)\n",
    "\n",
    "        high = self.all_conv_high[0](input)\n",
    "        low = self.all_conv_low[0](input)\n",
    "        ap_residual = self.all_residual[0](input)\n",
    "\n",
    "        # Time convolutions are concatenated along the feature maps axis\n",
    "        output = torch.cat([\n",
    "            high,\n",
    "            low,\n",
    "            ap_residual\n",
    "        ], dim=1)\n",
    "        N, C, F = output.size()\n",
    "        output = self.fc(output.view(N, C * F))\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(traininput, trainlabel, testinput, testlabel, batchsize):\n",
    "    traindata = addbatch(traininput, trainlabel, batchsize)  # shuffle打乱数据集\n",
    "    maxacc = 0\n",
    "    start=time.time()\n",
    "    for epoch in range(101):\n",
    "        for step, data in enumerate(traindata):\n",
    "            net.train()\n",
    "            inputs, labels = data\n",
    "            # 前向传播\n",
    "            out = net(inputs)\n",
    "            # 计算损失函数\n",
    "            loss = loss_func(out, labels)\n",
    "            # 清空上一轮的梯度\n",
    "            optimizer.zero_grad()\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 参数更新\n",
    "            optimizer.step()\n",
    "\n",
    "        # 测试准确率\n",
    "        net.eval()\n",
    "        testout = net(testinput)\n",
    "        testloss = loss_func(testout, testlabel)\n",
    "        prediction = torch.max(testout, 1)[1]  # torch.max\n",
    "        pred_y = prediction.numpy()\n",
    "        target_y = testlabel.data.numpy()\n",
    "        j = 0\n",
    "        for i in range(?):\n",
    "            if pred_y[i] == target_y[i]:\n",
    "                j += 1\n",
    "        acc = j / pred_y.size\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"训练次数为\", ?, \"的准确率为:\", ?)\n",
    "        if acc > maxacc:\n",
    "            torch.save(net.state_dict(), \"?\", _use_new_zipfile_serialization=False)\n",
    "            print('save '+ str(acc))\n",
    "            maxacc = ?\n",
    "\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码中已经完整定义了训练模型需要用到的各种函数(其中神经网络模型的具体代码保存在代码文件中)，接下来请同学们自行阅读理解上述代码，补全空缺部分（即？处）的代码，使代码能正确运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    feature, label = load_data('?')\n",
    "    split = ?  \n",
    "    ifshuffle = ?  \n",
    "    x_train, x_test, y_train, y_test = split_dataset(feature, label, split, ifshuffle)\n",
    "    traininput, trainlabel = inputtotensor(?, ?)\n",
    "    testinput, testlabel = inputtotensor(?, ?)\n",
    "    traininput = nn.functional.normalize(traininput)\n",
    "    testinput = nn.functional.normalize(?)\n",
    "    LR = ?          #（0.001~0.009）\n",
    "    batchsize = ?   #（2~10）\n",
    "    net = Net()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), LR)\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    train_test(traininput, trainlabel, testinput, testlabel, batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请同学们认真阅读理解各个参数的含义，自行设置参数，补全主函数中空缺的代码，训练手势识别神经网络模型达到尽可能高的准确率。在训练完成后，同学们可以将上述代码的最后一行train_test函数的调用注释掉，同时在下方添加以下代码，运行后即可加载训练好的模型，输出数据集中五类手势的混淆矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input, label = inputtotensor(feature, label)\n",
    "    input = nn.functional.normalize(input)\n",
    "    model = Net()\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(\"model.pt\"))\n",
    "    output = model(input)\n",
    "    pred = torch.max(output, 1)[1]\n",
    "    C = confusion_matrix(label, pred, labels=[0, 1, 2, 3, 4])\n",
    "    plt.matshow(C, cmap=plt.cm.Reds)\n",
    "    for i in range(len(C)):\n",
    "        for j in range(len(C)):\n",
    "            plt.annotate(C[j, i], xy=(i, j), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码为将训练好的模型部署到小车上的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "#camera = Camera.instance(width=224, height=224)\n",
    "camera = Camera.instance(width=224, height=224, fps=20)\n",
    "image = widgets.Image(format='jpg', width=224, height=224)\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示相机的实时画面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def data_calculate(image):\n",
    "    \n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True,\n",
    "                           max_num_hands=2,\n",
    "                           min_detection_confidence=0.5,\n",
    "                           min_tracking_confidence=0.5)\n",
    "    img = cv2.flip(image, 1)\n",
    "    # BGR to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input = []\n",
    "    results = hands.process(img)\n",
    "   \n",
    "    for i in results.multi_hand_landmarks[0].landmark:\n",
    "        input.extend([i.x, i.y, i.z])\n",
    "    \n",
    "    return input\n",
    "\n",
    "\n",
    "def inputtotensor(inputtensor):\n",
    "    inputtensor = np.array(inputtensor)\n",
    "    inputtensor = torch.FloatTensor(inputtensor)\n",
    "\n",
    "    return inputtensor\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_channels=63, n_classes=5, dropout_probability=0.2):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_probability = dropout_probability\n",
    "        self.all_conv_high = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=7, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "        self.all_conv_low = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "\n",
    "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "        self.all_residual = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2),\n",
    "            torch.nn.AvgPool1d(2)\n",
    "        )])\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=9 * 7, out_features=512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=512, out_features=n_classes)\n",
    "        )\n",
    "        for module in itertools.chain(self.all_conv_high, self.all_conv_low, self.all_residual):\n",
    "            for layer in module:\n",
    "                if layer.__class__.__name__ == \"Conv1d\":\n",
    "                    torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                    torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "        for layer in self.fc:\n",
    "            if layer.__class__.__name__ == \"Linear\":\n",
    "                torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
    "                torch.nn.init.constant_(layer.bias, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        input = input.unsqueeze(1)\n",
    "\n",
    "        high = self.all_conv_high[0](input)\n",
    "        low = self.all_conv_low[0](input)\n",
    "        ap_residual = self.all_residual[0](input)\n",
    "\n",
    "        # Time convolutions are concatenated along the feature maps axis\n",
    "        output = torch.cat([\n",
    "            high,\n",
    "            low,\n",
    "            ap_residual\n",
    "        ], dim=1)\n",
    "        N, C, F = output.size()\n",
    "        output = self.fc(output.view(N, C * F))\n",
    "\n",
    "        return output   \n",
    "\n",
    "def preprocess (x): \n",
    "    x = data_calculate(x)\n",
    "    x = inputtotensor(x)\n",
    "    x = x.view(1,63)\n",
    "    x = nn.functional.normalize(x)\n",
    "    return x\n",
    "\n",
    "model = Net()                             \n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了减少JetBot的运算负担，我们需要执行如下代码，用以取消摄像头的连接。 此时摄像头只是不推流到浏览器上，但在Jetbot上的摄像头仍然处于工作状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "robot = Robot()\n",
    "from RGB_Lib import Programing_RGB\n",
    "RGB = Programing_RGB()\n",
    "import RPi.GPIO as GPIO\n",
    "BEEP_pin = 6 \n",
    "GPIO.setmode(GPIO.BCM)\n",
    "# set pin as an output pin with optional initial state of HIGH\n",
    "GPIO.setup(BEEP_pin, GPIO.OUT, initial=GPIO.LOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用以上代码块创建驱动电机，RGB灯，蜂鸣器的robot实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global stop_slider, forward_slider,backward_slider,left_slider,right_slider,robot\n",
    "    t1 = time.time()\n",
    "    x = change['new'] \n",
    "    try:\n",
    "        x = preprocess(x)\n",
    "        output = model(x)\n",
    "        y = torch.max(output, 1)[1]\n",
    "        print(y)\n",
    "        if y == 0: \n",
    "            robot.stop()\n",
    "            GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "            RGB.Set_ChameleonLight_RGB()\n",
    "            RGB.OFF_ALL_RGB()\n",
    "        if y == 1:\n",
    "            robot.forward(0.4)\n",
    "            GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "            RGB.Set_BreathSColor_RGB(2)\n",
    "            RGB.Set_BreathSSpeed_RGB(1)\n",
    "            RGB.Set_BreathSLight_RGB()\n",
    "        if y == 2: \n",
    "            robot.backward(0.4)\n",
    "            RGB.OFF_ALL_RGB()\n",
    "            GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "            RGB.Set_An_RGB(4, 0xFF, 0x00, 0x00)\n",
    "        if y == 3: \n",
    "            robot.left(0.5)\n",
    "            RGB.OFF_ALL_RGB()\n",
    "            GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "            RGB.Set_An_RGB(9, 0xFF, 0x00, 0x00)\n",
    "        if y == 4: \n",
    "            robot.right(0.5)\n",
    "            GPIO.output(BEEP_pin, GPIO.LOW)\n",
    "            RGB.Set_All_RGB(0xFF, 0x00, 0x00)   \n",
    "    except:\n",
    "        robot.stop()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "update({'new': camera.value})  # we call the function once to intialize\n",
    "camera.observe(update, names='value') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们需要定义一个函数，每隔一定的时间采集一次手势图片，同时根据识别结果传输给小车相应的命令。同学们可以自行摸索定义上述代码中不同动作的灯光效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "停止小车运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
